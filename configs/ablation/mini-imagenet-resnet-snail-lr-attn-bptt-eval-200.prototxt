backbone_class: "resnet_backbone"
model_class: "attractor-bptt"
resnet_config: {
    height: 84
    width: 84
    num_channel: 3
    num_residual_units: 1
    num_residual_units: 1
    num_residual_units: 1
    num_residual_units: 1
    num_filters: 64
    num_filters: 64
    num_filters: 96
    num_filters: 128
    num_filters: 256
    strides: 2
    strides: 2
    strides: 2
    strides: 2
    init_stride: 1
    init_max_pool: false
    init_filter: 5
    use_bottleneck: false
    wd: 5e-4
    normalization: "batch_norm"
    global_avg_pool: true
    data_format: "NCHW"
    version: "snailv2"
    leaky_relu: 0.1
    filter_initialization: "normal"
    add_last_relu: false
}

protonet_config: {}

transfer_config: {
    finetune_layers: "none"
    dummy_lr: 1e0
    rbp_lambda: 1e-1
    rbp_nstep: 20
    finetune_wd: 1e-5
    old_and_new: true
    transfer_loss_type: "proto_attn_attr"
    transfer_loss_ratio: 1.0
    meta_only: true
    train_wclass_a: false
    replace_grad_wclass_a: false
    cost_a_ratio: 0.0
    cost_b_ratio: 1.0
    final_cost_a_ratio: 0.0
    reduce_slow_layers: 1.0
    cache_transfer_loss_var: false
    attn_attr_tau_init: 2.0
    mlp_hidden: 50
    init_gamma: 1e-1
    learn_gamma: true
    bptt_steps: 200
    transient_bptt: true
    steady_rbp: false
    ft_optimizer_config: {
        optimizer: "sgd"
        lr_decay_steps: 100
        max_train_steps: 200
        lr_list: 1e0
        lr_list: 1e0
        batch_size: -1
    }
}

optimizer_config: {
    optimizer: "adam"
    lr_decay_steps: 4000
    max_train_steps: 8000
    lr_list: 1e-3
    lr_list: 1e-4
    batch_size: 256
}

train_config: {
    steps_per_val: 1000
    steps_per_log: 10
    steps_per_save: 1000
}
